{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Armegas/4Geeks_Academy_RNA_Redes-de-Neuronas-Artificiales-clase-/blob/main/es_exploring_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQgwOwACHT5x"
      },
      "source": [
        "## RNA in Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4njqDX1HT5z"
      },
      "source": [
        "A continuación veremos cómo podemos implementar RNA (Redes de Neuronas Artificiales) en Python. Para ello, utilizaremos la librería keras sobre tensorflow (que es lo más común)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k418iES2HT5z"
      },
      "source": [
        "### Clasificación de conjuntos de datos textuales\n",
        "\n",
        "Vamos a utilizar el conjunto de datos de inicio de diabetes de los indios Pima. Este es un conjunto de datos de Machine Learning estándar del repositorio de Machine Learning de UCI. Describe los datos de los registros médicos de los pacientes de los indios Pima y si tuvieron un inicio de diabetes dentro de los cinco años."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyzG2dK_HT50"
      },
      "source": [
        "#### Paso 1. Lectura del conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GviNcgR7HT50",
        "outputId": "a752f3a6-26df-4efe-cf8a-86d403aae36e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "60  -0.547919 -1.154694 -3.572597 -1.288212 -0.692891 -4.060474 -0.507006   \n",
              "618  1.530847 -0.278373  0.666618  0.217261 -0.692891 -0.481351  2.446670   \n",
              "346 -0.844885  0.566649 -1.194501 -0.096379  0.027790 -0.417892  0.550035   \n",
              "294 -1.141852  1.255187 -0.987710 -1.288212 -0.692891 -1.280942 -0.658012   \n",
              "231  0.639947  0.410164  0.563223  1.032726  2.519781  1.803195 -0.706334   \n",
              "\n",
              "            7  \n",
              "60  -1.041549  \n",
              "618  1.425995  \n",
              "346 -0.956462  \n",
              "294  2.702312  \n",
              "231  1.085644  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ac5fcc1-b00b-4e38-9819-2f95d35ae707\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>-0.547919</td>\n",
              "      <td>-1.154694</td>\n",
              "      <td>-3.572597</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-4.060474</td>\n",
              "      <td>-0.507006</td>\n",
              "      <td>-1.041549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>1.530847</td>\n",
              "      <td>-0.278373</td>\n",
              "      <td>0.666618</td>\n",
              "      <td>0.217261</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-0.481351</td>\n",
              "      <td>2.446670</td>\n",
              "      <td>1.425995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>0.566649</td>\n",
              "      <td>-1.194501</td>\n",
              "      <td>-0.096379</td>\n",
              "      <td>0.027790</td>\n",
              "      <td>-0.417892</td>\n",
              "      <td>0.550035</td>\n",
              "      <td>-0.956462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>-1.141852</td>\n",
              "      <td>1.255187</td>\n",
              "      <td>-0.987710</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-1.280942</td>\n",
              "      <td>-0.658012</td>\n",
              "      <td>2.702312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>0.639947</td>\n",
              "      <td>0.410164</td>\n",
              "      <td>0.563223</td>\n",
              "      <td>1.032726</td>\n",
              "      <td>2.519781</td>\n",
              "      <td>1.803195</td>\n",
              "      <td>-0.706334</td>\n",
              "      <td>1.085644</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ac5fcc1-b00b-4e38-9819-2f95d35ae707')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ac5fcc1-b00b-4e38-9819-2f95d35ae707 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ac5fcc1-b00b-4e38-9819-2f95d35ae707');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d26840e6-8106-495d-b2fd-a9cf2d0e7789\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d26840e6-8106-495d-b2fd-a9cf2d0e7789')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d26840e6-8106-495d-b2fd-a9cf2d0e7789 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train",
              "summary": "{\n  \"name\": \"X_train\",\n  \"rows\": 614,\n  \"fields\": [\n    {\n      \"column\": \"0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9839283399243306,\n        \"min\": -1.1418515161634994,\n        \"max\": 3.906578350084603,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          -0.5479185907225461,\n          1.5308466483207903,\n          0.0460143347184071\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0026058263234612,\n        \"min\": -3.78365371377963,\n        \"max\": 2.444478206307916,\n        \"num_unique_values\": 133,\n        \"samples\": [\n          -0.9982077796701244,\n          -0.9669106343430512,\n          -1.874527848828171\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9570596922227715,\n        \"min\": -3.572597239872642,\n        \"max\": 2.734528247420465,\n        \"num_unique_values\": 44,\n        \"samples\": [\n          -1.0911052448720753,\n          -0.7809187454970045,\n          -0.5741277459136239\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9681432943275632,\n        \"min\": -1.2882122129452358,\n        \"max\": 2.6636556358464394,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.0290770699853224,\n          -0.410019357658197,\n          1.3463663529158807\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0092549778572062,\n        \"min\": -0.6928905722954675,\n        \"max\": 6.65283937836846,\n        \"num_unique_values\": 167,\n        \"samples\": [\n          1.2173465307140643,\n          0.9829083407992584,\n          -0.2674286720797081\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9824342934832846,\n        \"min\": -4.060473872668307,\n        \"max\": 4.455807490825071,\n        \"num_unique_values\": 225,\n        \"samples\": [\n          -1.6363162863385974,\n          -0.0117499457616192,\n          0.2547804694892914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.017317156703669,\n        \"min\": -1.1895531764897842,\n        \"max\": 5.88356476587794,\n        \"num_unique_values\": 443,\n        \"samples\": [\n          -0.2049944876717318,\n          -0.3922418456678032,\n          -0.6398915772109943\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9788015652111302,\n        \"min\": -1.0415494364835025,\n        \"max\": 4.063715751598595,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          0.7452933793452318,\n          1.0005566387493363,\n          1.6812586638269496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd # Importa la biblioteca pandas, que se usa para manipular y analizar datos de forma tabular (como hojas de cálculo).\n",
        "from sklearn.model_selection import train_test_split # Importa la función train_test_split de la biblioteca scikit-learn. Esta función se utiliza para dividir datos en conjuntos de entrenamiento y prueba.\n",
        "\n",
        "total_data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/machine-learning-content/master/assets/clean-pima-indians-diabetes.csv\") # Carga el conjunto de datos de diabetes Pima Indians desde un archivo CSV en una URL y lo almacena en un DataFrame de pandas llamado total_data.\n",
        "\n",
        "X = total_data.drop(\"8\", axis = 1) # Crea el DataFrame de características (X) eliminando la columna \"8\" del conjunto de datos. El argumento axis=1 indica que se está eliminando una columna, no una fila. La columna \"8\" representa la variable objetivo.\n",
        "y = total_data[\"8\"] # Crea la Serie de etiquetas o variable objetivo (y) seleccionando la columna \"8\" de los datos.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # Divide los datos en conjuntos de entrenamiento y prueba.\n",
        "# X_train, y_train: Conjuntos de entrenamiento (80% de los datos).\n",
        "# X_test, y_test: Conjuntos de prueba (20% de los datos, definido por test_size = 0.2).\n",
        "# random_state = 42: Asegura que la división de los datos sea la misma cada vez que se ejecuta el código, lo que hace el resultado reproducible.\n",
        "\n",
        "X_train.head() # Muestra las primeras cinco filas del conjunto de datos de entrenamiento (X_train) para verificar que la división se realizó correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L29f1DOYHT51"
      },
      "source": [
        "El conjunto train lo utilizaremos para entrenar el modelo, mientras que con el test lo evaluaremos para medir su grado de efectividad. Además, generalmente es una buena práctica normalizar los datos antes de entrenar una red neuronal artificial (RNA). Se pueden aplicar dos tipos: de 0 a 1 o de -1 a 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqc1RJUqHT51"
      },
      "source": [
        "#### Paso 2: Inicialización y entrenamiento del modelo\n",
        "\n",
        "Los modelos en Keras se definen como una secuencia de capas. Creamos un modelo secuencial y agregamos capas una a una hasta que estemos satisfechos con nuestra arquitectura de red.\n",
        "\n",
        "La capa de entrada siempre tendrá tantas neuronas como variables predictoras. En este caso, tenemos un total de 8 (de la 0 a la 7). A continuación, añadimos dos capas ocultas, una de 12 neuronas y otra de 8. Por último, la cuarta capa, de salida, tendrá una única neurona, ya que el problema es dicotómico. Si fuese de n clases, la red tendría n salidas.\n",
        "\n",
        "Nota: Hemos creado una red por defecto con capas ocultas y neuronas en cada capa oculta aleatorias. Normalmente se suele empezar así y a continuación hacer una optimización de hiperparámetros.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2dcn9LoHT51"
      },
      "outputs": [],
      "source": [
        "# Se importa la clase Dense del módulo de capas de Keras.\n",
        "# Una capa Dense (o completamente conectada) es la capa de neuronas más común y fundamental en una red neuronal.\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Se importa la clase Sequential del módulo de modelos de Keras.\n",
        "# Un modelo secuencial es una pila lineal de capas, lo que significa que las capas se añaden una tras otra. Es el tipo de modelo más simple.\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Se importa la función set_random_seed. Esto se usa para establecer una semilla aleatoria para que los resultados del modelo sean reproducibles.\n",
        "from tensorflow.keras.utils import set_random_seed\n",
        "\n",
        "# Se establece la semilla aleatoria en 42. Esto garantiza que cada vez que se ejecute el código,\n",
        "# la inicialización de los pesos de la red neuronal será la misma,\n",
        "# lo que permite obtener resultados consistentes.\n",
        "set_random_seed(42)\n",
        "\n",
        "# Se crea una instancia de un modelo secuencial y se asigna a la variable 'model'.\n",
        "model = Sequential()\n",
        "\n",
        "# Se añade la primera capa oculta al modelo.\n",
        "# Dense(12,...): Esta capa tendrá 12 neuronas.\n",
        "# input_shape=(8,): Define la forma de la entrada para esta capa. En este caso, la entrada es un vector de 8 elementos (las 8 características del conjunto de datos).\n",
        "# activation=\"relu\": La función de activación \"Rectified Linear Unit\" (ReLU) se aplica a las salidas de esta capa.\n",
        "model.add(Dense(12, input_shape = (8,), activation = \"relu\"))\n",
        "\n",
        "# Se añade una segunda capa oculta al modelo.\n",
        "# Dense(8,...): Esta capa tendrá 8 neuronas.\n",
        "# activation=\"relu\": También usa la función de activación ReLU.\n",
        "model.add(Dense(8, activation = \"relu\"))\n",
        "\n",
        "# Se añade la capa de salida al modelo.\n",
        "# Dense(1,...): Esta capa tiene una sola neurona, que es adecuada para una tarea de clasificación binaria (como la de este caso, ¿sí o no diabetes?).\n",
        "# activation=\"sigmoid\": La función de activación sigmoide comprime el resultado de la neurona de salida entre 0 y 1, lo que se puede interpretar como la probabilidad de que la entrada pertenezca a la clase positiva.\n",
        "model.add(Dense(1, activation = \"sigmoid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SVB0i1BHT52"
      },
      "source": [
        "A continuación, una vez que el modelo está definido, podemos compilarlo. El backend elige automáticamente la mejor manera de representar la red para entrenar y hacer predicciones para ejecutar en su hardware, como CPU o GPU o incluso distribuido.\n",
        "\n",
        "Al compilar, debemos especificar algunas propiedades adicionales requeridas al entrenar la red. Recordemos que entrenar una red significa encontrar el mejor conjunto de pesos para asignar entradas a salidas en nuestro conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh7n6_ceHT52",
        "outputId": "5f4e9cdb-2de7-47bc-e835-df0da0fbc3c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m108\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m221\u001b[0m (884.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221</span> (884.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m221\u001b[0m (884.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221</span> (884.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Este comando configura el proceso de entrenamiento del modelo.\n",
        "# Se le pasan tres argumentos clave:\n",
        "model.compile(\n",
        "    loss = \"binary_crossentropy\",  # 1. Función de pérdida: binary_crossentropy\n",
        "    optimizer = \"adam\",           # 2. Optimizador: adam\n",
        "    metrics = [\"accuracy\"]        # 3. Métricas: accuracy\n",
        ")\n",
        "\n",
        "# Muestra un resumen del modelo. Esto incluye las capas, el número de parámetros en cada capa y el número total de parámetros entrenables.\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPvAt-loHT52"
      },
      "source": [
        "Definiremos el optimizador conocido como adam. Esta es una versión popular del descenso de gradiente porque se sintoniza automáticamente y brinda buenos resultados en una amplia gama de problemas. Recopilaremos e informaremos la precisión de la clasificación, definida a través del argumento de las métricas.\n",
        "\n",
        "El entrenamiento ocurre en épocas (epoch) y cada época se divide en lotes (batch).\n",
        "\n",
        "Epoch: Una pasada por todas las filas del conjunto de datos de entrenamiento.\n",
        "Batch: Una o más muestras consideradas por el modelo dentro de una época antes de que se actualicen los pesos.\n",
        "El proceso de entrenamiento se ejecutará durante un número fijo de iteraciones, que son las épocas. También debemos establecer la cantidad de filas del conjunto de datos que se consideran antes de que se actualicen los pesos del modelo dentro de cada época, lo que se denomina tamaño de batch y se establece mediante el argumento batch_size (tamaño_lote).\n",
        "\n",
        "Para este problema, ejecutaremos una pequeña cantidad de epochs (150) y usaremos un tamaño de batch relativamente pequeño de 10:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRbCiF3rHT53",
        "outputId": "037c238f-063e-4fcf-9a03-f5d2dad3739b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.3911\n",
            "Epoch 2/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.3939\n",
            "Epoch 3/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.3939\n",
            "Epoch 4/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7974 - loss: 0.3937\n",
            "Epoch 5/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: 0.3934\n",
            "Epoch 6/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7974 - loss: 0.3934\n",
            "Epoch 7/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7957 - loss: 0.3927\n",
            "Epoch 8/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7979 - loss: 0.3928\n",
            "Epoch 9/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7981 - loss: 0.3923\n",
            "Epoch 10/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.3918\n",
            "Epoch 11/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.3918\n",
            "Epoch 12/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.3915\n",
            "Epoch 13/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.3908\n",
            "Epoch 14/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7989 - loss: 0.3907\n",
            "Epoch 15/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7989 - loss: 0.3901\n",
            "Epoch 16/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7981 - loss: 0.3899\n",
            "Epoch 17/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7989 - loss: 0.3897\n",
            "Epoch 18/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7973 - loss: 0.3891\n",
            "Epoch 19/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7990 - loss: 0.3883\n",
            "Epoch 20/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7997 - loss: 0.3857\n",
            "Epoch 21/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7995 - loss: 0.3841\n",
            "Epoch 22/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.3829\n",
            "Epoch 23/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.3814\n",
            "Epoch 24/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.3809\n",
            "Epoch 25/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.3804\n",
            "Epoch 26/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.3798\n",
            "Epoch 27/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.3792\n",
            "Epoch 28/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.3787\n",
            "Epoch 29/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8027 - loss: 0.3786\n",
            "Epoch 30/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8027 - loss: 0.3777\n",
            "Epoch 31/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8059 - loss: 0.3771\n",
            "Epoch 32/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8028 - loss: 0.3771\n",
            "Epoch 33/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.3762\n",
            "Epoch 34/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - loss: 0.3761\n",
            "Epoch 35/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.3756\n",
            "Epoch 36/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.3749\n",
            "Epoch 37/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.3750\n",
            "Epoch 38/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.3739\n",
            "Epoch 39/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8069 - loss: 0.3741\n",
            "Epoch 40/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.3733\n",
            "Epoch 41/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8060 - loss: 0.3731\n",
            "Epoch 42/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8066 - loss: 0.3727\n",
            "Epoch 43/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8062 - loss: 0.3721\n",
            "Epoch 44/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.3722\n",
            "Epoch 45/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8073 - loss: 0.3713\n",
            "Epoch 46/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.3714\n",
            "Epoch 47/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.3707\n",
            "Epoch 48/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.3703\n",
            "Epoch 49/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8072 - loss: 0.3703\n",
            "Epoch 50/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8058 - loss: 0.3697\n",
            "Epoch 51/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.3695\n",
            "Epoch 52/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.3691\n",
            "Epoch 53/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.3688\n",
            "Epoch 54/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.3681\n",
            "Epoch 55/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8063 - loss: 0.3678\n",
            "Epoch 56/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8054 - loss: 0.3678\n",
            "Epoch 57/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8063 - loss: 0.3672\n",
            "Epoch 58/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8065 - loss: 0.3665\n",
            "Epoch 59/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.3665\n",
            "Epoch 60/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8071 - loss: 0.3662\n",
            "Epoch 61/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8068 - loss: 0.3656\n",
            "Epoch 62/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8068 - loss: 0.3653\n",
            "Epoch 63/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.3649\n",
            "Epoch 64/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8104 - loss: 0.3643\n",
            "Epoch 65/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8112 - loss: 0.3642\n",
            "Epoch 66/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.3635\n",
            "Epoch 67/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8133 - loss: 0.3631\n",
            "Epoch 68/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8124 - loss: 0.3623\n",
            "Epoch 69/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8119 - loss: 0.3621\n",
            "Epoch 70/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8124 - loss: 0.3620\n",
            "Epoch 71/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8138 - loss: 0.3616\n",
            "Epoch 72/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.3611\n",
            "Epoch 73/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.3608\n",
            "Epoch 74/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.3602\n",
            "Epoch 75/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.3599\n",
            "Epoch 76/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.3598\n",
            "Epoch 77/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.3589\n",
            "Epoch 78/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.3587\n",
            "Epoch 79/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.3585\n",
            "Epoch 80/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8205 - loss: 0.3580\n",
            "Epoch 81/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.3578\n",
            "Epoch 82/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.3574\n",
            "Epoch 83/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.3573\n",
            "Epoch 84/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.3566\n",
            "Epoch 85/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.3566\n",
            "Epoch 86/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.3559\n",
            "Epoch 87/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8215 - loss: 0.3559\n",
            "Epoch 88/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8238 - loss: 0.3554\n",
            "Epoch 89/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.3552\n",
            "Epoch 90/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8264 - loss: 0.3550\n",
            "Epoch 91/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3543\n",
            "Epoch 92/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3543\n",
            "Epoch 93/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8228 - loss: 0.3539\n",
            "Epoch 94/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.3534\n",
            "Epoch 95/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.3532\n",
            "Epoch 96/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.3529\n",
            "Epoch 97/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.3529\n",
            "Epoch 98/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.3524\n",
            "Epoch 99/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8246 - loss: 0.3526\n",
            "Epoch 100/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.3523\n",
            "Epoch 101/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8164 - loss: 0.3520\n",
            "Epoch 102/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8207 - loss: 0.3520\n",
            "Epoch 103/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8168 - loss: 0.3517\n",
            "Epoch 104/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.3514\n",
            "Epoch 105/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3510\n",
            "Epoch 106/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.3509\n",
            "Epoch 107/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.3509\n",
            "Epoch 108/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.3503\n",
            "Epoch 109/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8199 - loss: 0.3501\n",
            "Epoch 110/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8199 - loss: 0.3498\n",
            "Epoch 111/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3497\n",
            "Epoch 112/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3495\n",
            "Epoch 113/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3494\n",
            "Epoch 114/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8199 - loss: 0.3492\n",
            "Epoch 115/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3486\n",
            "Epoch 116/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.3483\n",
            "Epoch 117/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.3481\n",
            "Epoch 118/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8286 - loss: 0.3479\n",
            "Epoch 119/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.3474\n",
            "Epoch 120/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8266 - loss: 0.3475\n",
            "Epoch 121/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8341 - loss: 0.3469\n",
            "Epoch 122/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.3465\n",
            "Epoch 123/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3463\n",
            "Epoch 124/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3461\n",
            "Epoch 125/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3457\n",
            "Epoch 126/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.3459\n",
            "Epoch 127/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3457\n",
            "Epoch 128/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.3444\n",
            "Epoch 129/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.3450\n",
            "Epoch 130/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8324 - loss: 0.3445\n",
            "Epoch 131/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.3443\n",
            "Epoch 132/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8348 - loss: 0.3435\n",
            "Epoch 133/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3435\n",
            "Epoch 134/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3427\n",
            "Epoch 135/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3428\n",
            "Epoch 136/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3423\n",
            "Epoch 137/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3419\n",
            "Epoch 138/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8389 - loss: 0.3422\n",
            "Epoch 139/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3418\n",
            "Epoch 140/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8381 - loss: 0.3415\n",
            "Epoch 141/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8347 - loss: 0.3409\n",
            "Epoch 142/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3399\n",
            "Epoch 143/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8356 - loss: 0.3403\n",
            "Epoch 144/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3393\n",
            "Epoch 145/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8386 - loss: 0.3390\n",
            "Epoch 146/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8356 - loss: 0.3387\n",
            "Epoch 147/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8370 - loss: 0.3385\n",
            "Epoch 148/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8434 - loss: 0.3381\n",
            "Epoch 149/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8404 - loss: 0.3376\n",
            "Epoch 150/150\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8434 - loss: 0.3371\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e3575e9e360>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Este comando inicia el proceso de entrenamiento del modelo.\n",
        "# Se le pasan los conjuntos de datos de entrenamiento (características y etiquetas)\n",
        "# y se especifican parámetros clave para el entrenamiento.\n",
        "model.fit(\n",
        "    X_train,     # 1. Los datos de entrenamiento (características)\n",
        "    y_train,     # 2. Las etiquetas de entrenamiento (la variable objetivo)\n",
        "    epochs = 150,# 3. Número de épocas: cuántas veces el algoritmo recorrerá todo el conjunto de datos de entrenamiento\n",
        "    batch_size = 10# 4. Tamaño del lote: cuántas muestras se usarán en cada paso de actualización del modelo.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp0o-iMQHT53",
        "outputId": "8262bb36-bd83-4f12-bb38-f52f77e500ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8519 - loss: 0.3088  \n",
            "Accuracy: 0.8583061695098877\n"
          ]
        }
      ],
      "source": [
        "# Evalúa el modelo en el conjunto de datos de entrenamiento (X_train, y_train).\n",
        "# Devuelve la pérdida y las métricas (como la precisión).\n",
        "_, accuracy = model.evaluate(X_train, y_train)\n",
        "\n",
        "# Imprime la precisión del modelo en la terminal, formateada como un porcentaje.\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wPvLmImHT53"
      },
      "source": [
        "El tiempo de entrenamiento de un modelo dependerá, en primer lugar, del tamaño del conjunto de datos (instancias y características), y también de la tipología de modelo y su configuración.\n",
        "\n",
        "El accuracy del conjunto de entrenamiento es de un 84,20%.\n",
        "\n",
        "#### Paso 3: Predicción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU4r4Z-EHT53",
        "outputId": "844bd35b-5413-4777-e970-49d51ec298cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13090663],\n",
              "       [0.02762299],\n",
              "       [0.07976675],\n",
              "       [0.5106946 ],\n",
              "       [0.3687225 ],\n",
              "       [0.7348838 ],\n",
              "       [0.00241285],\n",
              "       [0.00305427],\n",
              "       [0.9401702 ],\n",
              "       [0.18566978],\n",
              "       [0.16093999],\n",
              "       [0.8827251 ],\n",
              "       [0.14474158],\n",
              "       [0.3935397 ],\n",
              "       [0.13409334]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Realiza predicciones sobre el conjunto de datos de prueba (X_test) usando el modelo.\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Muestra las primeras 15 predicciones (valores) del array y_pred.\n",
        "y_pred[:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fySV4W26HT54"
      },
      "source": [
        "Como vemos, el modelo no devuelve las clases 0 y 1 directamente, sino que requiere de un preprocesamiento previo:\n",
        "\n",
        "El código redondea las predicciones de probabilidad del modelo y muestra las primeras 15."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ydTLdEAHT54",
        "outputId": "dbcddff9-84fb-4593-c760-9aad56dea5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# y_pred es una lista de listas, por lo que x[0] accede al valor de probabilidad dentro de cada lista.\n",
        "# La función round() redondea cada probabilidad al número entero más cercano (0 o 1).\n",
        "# Esto convierte las probabilidades en predicciones binarias (0 = sin diabetes, 1 = con diabetes).\n",
        "y_pred_round = [round(x[0]) for x in y_pred]\n",
        "\n",
        "# Muestra los primeros 15 valores del array y_pred_round.\n",
        "# Estos valores serán 0 o 1, lo que representa las predicciones finales del modelo.\n",
        "y_pred_round[:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFbLyOkVHT54"
      },
      "source": [
        "Con los datos en crudo es muy complicado saber si el modelo está acertando o no. Para ello, debemos compararlo con la realidad. Existe una gran cantidad de métricas para medir la efectividad de un modelo a la hora de predecir, entre ellas la precisión (accuracy), que es la fracción de predicciones que el modelo realizó correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoTVf4WlHT54",
        "outputId": "5df4258f-a679-4bbe-feb5-bdd50ac3c1cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7077922077922078"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Importa la función accuracy_score de la biblioteca scikit-learn.\n",
        "# Esta función se usa para calcular la precisión de un modelo de clasificación.\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Compara las etiquetas reales del conjunto de prueba (y_test) con las predicciones del modelo (y_pred_round).\n",
        "# El resultado es un valor decimal que representa la proporción de predicciones correctas.\n",
        "accuracy_score(y_test, y_pred_round)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I31UfAoDHT54"
      },
      "source": [
        "#### Paso 4: Guardado del modelo\n",
        "\n",
        "Una vez tenemos el modelo que estábamos buscando (presumiblemente tras la optimización de hiperparámetros), para poder utilizarlo a futuro es necesario almacenarlo en nuestro directorio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCtUfehiHT55"
      },
      "outputs": [],
      "source": [
        "model.save(\"keras_8-12-8-1_42.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tTil_h3HT55"
      },
      "source": [
        "Añadir un nombre explicativo al modelo es vital, ya que en el caso de perder el código que lo ha generado sabremos qué arquitectura tiene (en este caso decimos 8-12-8-1 porque tiene 8 neuronas en la capa de entrada, 12 y 8 en las dos capas ocultas y una neurona en la capa de salida) y además la semilla para replicar los componentes aleatorios del modelo, que en este caso lo hacemos añadiendo un número al nombre del archivo, el 42."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnPbmsCPHT55"
      },
      "source": [
        "### Image set classification\n",
        "\n",
        "The following is a simple example of how to train a neural network to classify images from the MNIST dataset. MNIST is a dataset of images of handwritten digits, from 0 to 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I219HrMJHT55"
      },
      "source": [
        "#### Step 1. Reading the data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AigXaLwzHT55"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data (transform pixel values from 0-255 to 0-1)\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68h7uB_dHT56"
      },
      "source": [
        "The pixel values of the images are normalized to be in the range 0 to 1 instead of 0 to 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaLtT5zXHT56"
      },
      "source": [
        "#### Step 2: Model initialization and training\n",
        "\n",
        "The architecture of the neural network is defined. In this case, we are using a simple sequential model with a flattening layer that transforms 2D images into 1D vectors, a dense layer with 128 neurons, and an output layer with 10 neurons.\n",
        "\n",
        "An alternative way to create an ANN to the above is provided below. Both are valid:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ-C41GeHT56"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "set_random_seed(42)\n",
        "\n",
        "model = Sequential([\n",
        "  # Layer that flattens the 28x28 pixel input image to a vector of 784 elements\n",
        "  Flatten(input_shape = (28, 28)),\n",
        "  # Dense hidden layer with 128 neurons and ReLU activation function\n",
        "  Dense(128, activation = \"relu\"),\n",
        "  # Output layer with 10 neurons (one for each digit from 0 to 9)\n",
        "  Dense(10)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URY1xWpcHT56"
      },
      "source": [
        "We also added the network compiler to define the optimizer and the loss function, as we did before:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsMDRdH2HT57"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = SparseCategoricalCrossentropy(from_logits = True), metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaz_LanfHT57"
      },
      "source": [
        "The model is trained on the training set for a certain number of epochs. When working with images, it is less common to use the `batch_size` parameter:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF5lIRCxHT57",
        "outputId": "3d9200fe-7d37-416e-d638-35ef15024d6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2530 - accuracy: 0.9276\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1111 - accuracy: 0.9671\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0759 - accuracy: 0.9757\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0566 - accuracy: 0.9831\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0432 - accuracy: 0.9865\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fa9704ed010>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGygM2LBHT57",
        "outputId": "293bbf3d-a522-4ed4-bba3-5c26405710d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 1s 669us/step - loss: 0.0441 - accuracy: 0.9858\n",
            "Accuracy: 0.9858166575431824\n"
          ]
        }
      ],
      "source": [
        "_, accuracy = model.evaluate(X_train, y_train)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QOsEuwCHT58"
      },
      "source": [
        "The training time of a model will depend, first of all, on the size of the dataset (instances and features), and also on the type of model and its configuration.\n",
        "\n",
        "#### Step 3: Model prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1u1gy-vHT58",
        "outputId": "f70b40ac-e4df-4b29-a3b4-088137a0719f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 - 0s - loss: 0.0841 - accuracy: 0.9751 - 271ms/epoch - 867us/step\n",
            "\n",
            "Test accuracy: 0.9750999808311462\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjO34qCVHT58"
      },
      "source": [
        "#### Step 4: Saving the model\n",
        "\n",
        "Once we have the model we were looking for (presumably after hyperparameter optimization), to be able to use it in the future, it is necessary to store it in our directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3FvfMzXHT58"
      },
      "outputs": [],
      "source": [
        "model.save(\"keras_28x28-128-10_42.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf5E3l1wHT58"
      },
      "source": [
        "Adding an explanatory name to the model is vital, since in the case of losing the code that has generated it we will know what architecture it has (in this case we say `28x28-128-10` because it has an input layer of 28 x 28 pixels, 128 neurons in the only hidden layer it has, and 10 neurons in the output layer) and also the seed to replicate the random components of the model, which in this case we do by adding a number to the file name, `42`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('3.8.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}